# üöÄ Multi-Agent Financial Analysis System

> A production-ready, AI-powered multi-agent system with advanced SQL capabilities, featuring natural language querying, intelligent financial analysis, multi-database discovery, file upload processing, and modern Gemini-style UI.

## ‚ú® Overview

This sophisticated multi-agent financial analysis system combines the power of specialized AI agents to provide comprehensive financial insights. Built on a robust multi-tenant SQL foundation, it enables users to query databases using natural language, get expert financial analysis, research current market data, and receive beautifully formatted reports - all through an intelligent multi-agent orchestration system.

### üéØ **What Makes This Special:**
- **Multi-Agent Intelligence**: 5 specialized agents working together for comprehensive analysis
- **Financial Expertise**: Dedicated mutual fund and investment analysis capabilities
- **Dynamic Database Discovery**: Automatically discovers and maps multiple databases
- **Schema-per-Tenant**: Enterprise-grade multi-tenant architecture with data isolation
- **Real-Time Processing**: Streaming updates and real-time agent coordination
- **Production Ready**: Modular, configurable, and extensible architecture

## ü§ñ Multi-Agent System Features

### üéÜ **Intelligent Agent Orchestration**
- **OrchestratorAgent**: Main coordinator that analyzes queries and routes to appropriate agents
- **Dynamic Workflow Selection**: Automatically chooses between 5+ workflow types based on query complexity
- **Real-Time Coordination**: Agents communicate and collaborate in real-time
- **Intelligent Routing**: Smart decision-making on which agents to involve
- **Session Management**: Maintains conversation context across multi-turn interactions

### üìä **Specialized Financial Agents**
- **SQLAgentWrapper**: Enhanced integration with existing multi-database SQL infrastructure
- **MutualFundExpertAgent**: Dedicated Indian mutual fund analysis with investment insights
- **WebAgent**: Current market research and financial news gathering
- **DataFormatterAgent**: Beautiful chart generation and professional report formatting
- **Expert Analysis**: Deep financial insights with context-aware recommendations

### üîÑ **Advanced Workflow Management**
- **Simple Query**: Direct SQL queries with intelligent formatting
- **Full Analysis with Web**: Comprehensive analysis combining database + market research
- **Comparison Analysis**: Side-by-side fund/investment comparisons
- **Portfolio Analysis**: Portfolio-level insights and recommendations
- **Performance Analysis**: Detailed performance analysis with benchmarking

### üåç **Multi-Agent API Endpoints**
- `POST /multi-agent/query` - Process queries through multi-agent system
- `POST /multi-agent/query/stream` - Real-time streaming updates
- `GET /multi-agent/health` - Comprehensive system health monitoring
- `GET /multi-agent/workflows` - Available workflows and capabilities
- `POST /multi-agent/agents/refresh/{user_email}` - Agent cache management
- `GET /multi-agent/agents/status` - Detailed agent status and statistics
- `GET /multi-agent/config` - System configuration and feature toggles

### ‚öôÔ∏è **Configuration & Customization**
- **Environment-Based Configuration**: Easy tuning without code changes
- **Feature Toggles**: Enable/disable agents and capabilities
- **Timeout & Iteration Control**: Configurable safety limits
- **Model Selection**: Choose between different AI models
- **Expert Prompts**: Editable agent prompts and behaviors

## üéØ Traditional SQL Agent Features

### üè¢ **Multi-Tenant Architecture**
- **Schema-per-Tenant**: Advanced multi-tenant isolation with dedicated database schemas
- **Database-per-Tenant**: Backward compatibility with legacy user databases
- **Smart Migration**: Automatic migration between architectures with zero downtime
- **Session Management**: Secure JWT-based authentication with Google OAuth
- **Feature Flags**: Gradual rollout capabilities for new features

### ü§ñ **AI-Powered SQL Generation**
- **Natural Language Processing**: Ask questions in plain English, get SQL results
- **Intelligent Database Routing**: Automatically determines which database/schema to query
- **Context-Aware Responses**: Understands data relationships and provides meaningful insights
- **Advanced Query Optimization**: Generates efficient SQL with proper joins and filters
- **Error Handling**: Intelligent error recovery and query refinement

### üìÅ **File Upload & Processing**
- **Multi-Format Support**: Excel (.xlsx, .xls) and CSV files
- **Multi-Sheet Processing**: Handles Excel files with multiple sheets automatically
- **Asynchronous Processing**: Celery-based background processing with Redis
- **Real-time Status**: WebSocket-like updates on upload progress
- **Data Validation**: Comprehensive validation and error handling
- **Schema Detection**: Automatic data type inference and table creation

### üé® **Modern Gemini-Style UI**
- **Clean Interface**: Google Gemini-inspired design with collapsible sidebar
- **Responsive Design**: Mobile-first approach with Tailwind CSS
- **Real-time Chat**: Modern chat interface with message history
- **File Management**: Integrated file upload with attachment preview
- **Data Preview**: Right sidebar showing database table contents
- **Authentication**: Seamless Google OAuth integration

### üèóÔ∏è **Production-Ready Architecture**
- **FastAPI Backend**: High-performance async API with automatic OpenAPI docs
- **Next.js Frontend**: Server-side rendering with TypeScript
- **PostgreSQL**: Robust database with multi-tenant support
- **Celery + Redis**: Distributed task processing with monitoring
- **Docker Integration**: Containerized services for easy deployment
- **Monitoring**: Flower dashboard for task monitoring

## üèóÔ∏è System Architecture

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[Next.js App<br/>Port: 3001] --> B[Authentication<br/>Google OAuth]
        A --> C[Chat Interface<br/>Gemini Style]
        A --> D[File Upload<br/>Drag & Drop]
    end
    
    subgraph "API Layer"
        E[FastAPI Server<br/>Port: 8001] --> F[JWT Auth<br/>Middleware]
        E --> G[Multi-Agent API<br/>Endpoints]
        E --> H[Traditional SQL<br/>Endpoints]
        E --> I[File Processing<br/>Endpoints]
    end
    
    subgraph "Multi-Agent Intelligence Layer"
        J[MultiAgentOrchestrator<br/>Main Coordinator] --> K[SQLAgentWrapper<br/>Database Queries]
        J --> L[MutualFundExpert<br/>Financial Analysis]
        J --> M[WebAgent<br/>Market Research]
        J --> N[DataFormatter<br/>Visualization]
        O[MultiAgentService<br/>Business Logic] --> J
        P[Configuration<br/>Environment Variables] --> J
    end
    
    subgraph "Task Processing"
        Q[Celery Workers<br/>Background Tasks] --> R[File Processing<br/>Queue]
        Q --> S[Query Processing<br/>Queue]
        Q --> T[Maintenance<br/>Queue]
        U[Redis Broker<br/>Port: 6379] --> Q
        V[Flower Dashboard<br/>Port: 5555] --> Q
    end
    
    subgraph "Database Layer"
        W[PostgreSQL<br/>Multi-tenant]
        X[portfoliosql<br/>Shared Schema]
        Y[user_schema_*<br/>Tenant Schemas]
        Z[user_db_*<br/>Legacy DBs]
        AA[Discovery Service<br/>4+ Databases]
    end
    
    A --> E
    E --> G
    G --> O
    O --> K
    K --> W
    E --> Q
    W --> X
    W --> Y
    W --> Z
    K --> AA
```

### üóÑÔ∏è Database Architecture

**Multi-Tenant Database Strategy:**

1. **portfoliosql**: Central database with schema-per-tenant architecture
   - `public` schema: Shared portfolio/financial data
   - `user_schema_{id}`: Individual tenant schemas for uploaded data
   - `tenants` table: Tenant management and mapping
   - `chat_history` table: Persistent chat history storage

2. **user_db_{hash}**: Legacy database-per-tenant (backward compatibility)
   - Individual PostgreSQL databases for existing users
   - Automatic migration to schema-per-tenant available
   - Zero-downtime migration with feature flags

3. **Smart Database Routing**: Intelligent selection between architectures
   - Feature flags control migration rollout
   - Automatic fallback to legacy system
   - Seamless user experience during transition

## ü§ñ Multi-Agent System Configuration

### üìä **Environment Variables for Multi-Agent System**

```bash
# === OpenAI Configuration ===
OPENAI_API_KEY=your_openai_api_key_here
AGENT_MODEL=gpt-4o
AGENT_TEMPERATURE=0.3
AGENT_MAX_TOKENS=3000

# === Orchestrator Configuration ===
MAX_AGENT_ITERATIONS=10
AGENT_TIMEOUT_SECONDS=300
ENABLE_AGENT_CACHING=true

# === Feature Toggles ===
ENABLE_WEB_RESEARCH=true
WEB_SEARCH_ENABLED=false
ENABLE_CHART_GENERATION=true
MUTUAL_FUND_EXPERT_ENABLED=true

# === Web Agent Configuration ===
WEB_SCRAPING_TIMEOUT=30
MAX_WEB_SOURCES=5

# === Data Formatter Configuration ===
MAX_CHART_DATA_POINTS=100

# === Expert Agent Configuration ===
FINANCIAL_ANALYSIS_DEPTH=comprehensive
```

### üîß **Multi-Agent System Usage Examples**

**1. Simple Query Processing:**
```bash
curl -X POST http://localhost:8001/multi-agent/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the top performing large cap mutual funds?",
    "user_email": "user@example.com",
    "enable_caching": true
  }'
```

**2. Streaming Analysis:**
```bash
curl -X POST http://localhost:8001/multi-agent/query/stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Compare HDFC Top 100 and ICICI Prudential Bluechip funds",
    "user_email": "user@example.com"
  }'
```

**3. System Health Check:**
```bash
curl -X GET http://localhost:8001/multi-agent/health
```

**4. Available Workflows:**
```bash
curl -X GET http://localhost:8001/multi-agent/workflows
```

### üîç **Multi-Agent Workflow Types**

1. **simple_query**: Direct SQL queries with intelligent formatting
2. **full_analysis_with_web**: Comprehensive analysis with market research
3. **comparison_analysis**: Side-by-side fund/investment comparisons
4. **portfolio_analysis**: Portfolio-level insights and recommendations
5. **performance_analysis**: Detailed performance analysis with benchmarking

## üöÄ Quick Start

### üìã Prerequisites
- **Python 3.8+** with pip
- **Node.js 18+** with npm
- **PostgreSQL 12+**
- **Redis 6+** (for task processing)
- **Docker** (optional, for Redis)

### ‚öôÔ∏è Environment Setup

**1. Clone and Setup Python Environment:**
```bash
git clone <repository-url>
cd sql_agent_project_v4_multitenant
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

**2. Configure Environment Variables:**
```bash
cp .env.example .env
# Edit .env with your configuration
```

**Required Environment Variables:**
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
LANGCHAIN_API_KEY=your_langchain_api_key  # Optional for tracing

# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/portfoliosql
PORTFOLIOSQL_DATABASE_URI=postgresql://username:password@localhost:5432/portfoliosql
DB_HOST=localhost
DB_PORT=5432
DB_USER=your_db_user
DB_PASSWORD=your_db_password

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
DEBUG=True

# Security
SECRET_KEY=your_secret_key_here
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=480

# Google OAuth
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Feature Flags
ENABLE_SCHEMA_PER_TENANT=true
ENABLE_AUTO_MIGRATION=true
```

**3. Database Setup:**
```sql
-- Create the central database
CREATE DATABASE portfoliosql;

-- Initialize schema-per-tenant structure
python initialize_schema_per_tenant.py
```

**4. Redis Setup:**
```bash
# Option 1: Using Docker (Recommended)
docker-compose up -d redis

# Option 2: Local Redis installation
# Install Redis locally and start service
```

**5. Frontend Setup:**
```bash
cd frontend
npm install
npm run build
cd ..
```

## üé¨ Running the Application

### ü§ñ **Option 1: Multi-Agent System (Recommended)**
```bash
python start_multi_agent_server.py
```
**Starts multi-agent system with:**
- ‚úÖ FastAPI backend with multi-agent endpoints (http://localhost:8001)
- ‚úÖ 5 Specialized AI agents (SQL, Expert, Web, Formatter, Orchestrator)
- ‚úÖ Real-time streaming capabilities
- ‚úÖ Dynamic workflow selection
- ‚úÖ Multi-database discovery (4+ databases)
- ‚úÖ API Documentation: http://localhost:8001/docs
- ‚úÖ Multi-agent health check: http://localhost:8001/multi-agent/health

### üî• **Option 2: Full Production Mode**
```bash
python start_production.py
```
**Starts all services:**
- ‚úÖ Redis broker
- ‚úÖ FastAPI backend (http://localhost:8001)
- ‚úÖ Next.js frontend (http://localhost:3001)
- ‚úÖ Celery workers (background processing)
- ‚úÖ Celery beat (scheduled tasks)
- ‚úÖ Flower dashboard (http://localhost:5555)
- ‚úÖ Multi-agent system integrated

### üõ†Ô∏è **Option 2: Development Mode**
```bash
python start_multitenant.py
```
**Starts basic services:**
- ‚úÖ FastAPI backend (http://localhost:8001)
- ‚úÖ Next.js frontend (http://localhost:3001)
- ‚ö†Ô∏è **Note**: Start Celery workers separately for full functionality

### ‚ö° **Option 4: Individual Components**
```bash
# Terminal 1: Backend API
python -m uvicorn multitenant_api:app --host 0.0.0.0 --port 8001 --reload

# Terminal 2: Celery Worker (Essential for file uploads)
python start_celery_worker.py

# Terminal 3: Celery Beat (Optional - for maintenance tasks)
python start_celery_beat.py

# Terminal 4: Flower Monitoring (Optional)
python start_celery_flower.py

# Terminal 5: Frontend
cd frontend && npm run dev
```

### üåê Access Points
- **üé® Frontend Application**: http://localhost:3001
- **üîß API Documentation**: http://localhost:8001/docs
- **üìö API Redoc**: http://localhost:8001/redoc
- **üå∏ Flower Dashboard**: http://localhost:5555 (admin/password)
- **‚ö° Redis**: localhost:6379

## üìö API Documentation

### üîë Authentication Endpoints
```http
GET /auth/google/login
# Initiate Google OAuth login flow

GET /auth/google/callback
# Handle Google OAuth callback

GET /auth/me
# Get current user information
Authorization: Bearer {jwt_token}
```

### üìÅ File Upload Endpoints
```http
POST /upload-files
# Upload Excel/CSV files for processing
Content-Type: multipart/form-data
Authorization: Bearer {jwt_token}
Body: files[]
```

```http
GET /task-status/{task_id}
# Check background task status
Authorization: Bearer {jwt_token}
```

### üîç Query Endpoints
```http
POST /query
# Natural language database queries
Authorization: Bearer {jwt_token}
Content-Type: application/json
{
  "query": "Show me the top 10 products by sales",
  "session_id": "optional_session_id"
}
```

### üóÑÔ∏è User Data Management
```http
GET /user/tables
# List user's uploaded tables
Authorization: Bearer {jwt_token}

GET /user/databases
# List available databases for user
Authorization: Bearer {jwt_token}
```

### üîÑ Migration Endpoints
```http
GET /migration/status
# Check user's migration status
Authorization: Bearer {jwt_token}

POST /migration/trigger
# Manually trigger migration to schema-per-tenant
Authorization: Bearer {jwt_token}
```

### ‚ù§Ô∏è Health Check
```http
GET /health
# API health status (no authentication required)
```

### üì¶ Response Formats

**Successful Query Response:**
```json
{
  "success": true,
  "result": [
    {"product": "Widget A", "sales": 15000},
    {"product": "Widget B", "sales": 12000}
  ],
  "query_used": "SELECT product, sales FROM products ORDER BY sales DESC LIMIT 2",
  "explanation": "Retrieved top products by sales from your uploaded data.",
  "execution_time": 0.043
}
```

**File Upload Task Status:**
```json
{
  "task_id": "60021753-7e6e-4e5c-aee4-39f55eedd934",
  "status": "SUCCESS",
  "progress": 100,
  "message": "File processing completed successfully",
  "result": {
    "tables_created": 6,
    "total_rows": 97,
    "processing_time": 2.34,
    "sheets": ["Products", "Orders", "Customers"]
  }
}
```

**Authentication Response:**
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
  "token_type": "bearer",
  "expires_in": 28800,
  "user": {
    "id": "user123",
    "email": "user@example.com",
    "name": "John Doe"
  }
}
```

## üéÜ Usage Examples

### üîë **Authentication Flow**
1. Visit **http://localhost:3001**
2. Click **"Continue with Google"**
3. Complete OAuth flow in popup
4. Automatically redirected to chat interface

### üìÅ **File Upload Workflow**
1. **Click attachment button** (üìé) in chat input
2. **Select Excel/CSV files** (supports multi-sheet Excel)
3. **Files upload automatically** with real-time progress
4. **Background processing** creates database tables
5. **Chat confirmation** shows tables created and row counts

### üí¨ **Chat Interface Usage**

**Query Your Uploaded Data:**
```
üìã "Show me the top 10 products by sales volume"
üìä "What's the average order value by customer segment?"
üìà "Create a summary of monthly revenue trends"
üéØ "Which customers have the highest lifetime value?"
```

**Query Portfolio/Market Data:**
```
üíπ "What tech stocks are performing best this quarter?"
üí∞ "Show me dividend-paying stocks with yield > 3%"
üìâ "Compare sector performance year-to-date"
üåç "What are the top emerging market investments?"
```

**Cross-Database Analysis:**
```
üîÑ "How does my business revenue correlate with market trends?"
ü§ù "Compare my sales performance with industry benchmarks"
üîç "Find patterns between my customer data and economic indicators"
```

### üé® **Modern UI Features**
- **üß† Sidebar Navigation**: Hover to expand, shows chat history
- **üìù Message Bubbles**: Clean Gemini-style conversation flow
- **üìè File Attachments**: Drag-and-drop or click to upload
- **üîÑ Real-time Updates**: Live progress tracking
- **üì± Responsive Design**: Works on desktop, tablet, and mobile
- **üåô Dark/Light Theme**: Automatic theme detection

## ‚öôÔ∏è Configuration

### üóÑÔ∏è **Database Architecture**
- **Central Database**: `portfoliosql` with schema-per-tenant
- **Legacy Support**: `user_db_{hash}` databases with migration path
- **Smart Routing**: Automatic selection based on feature flags
- **Connection Pooling**: SQLAlchemy with async support

### üîí **Security Configuration**
- **JWT Authentication**: 8-hour token expiry
- **Google OAuth**: Secure third-party authentication
- **Environment Variables**: All secrets externalized
- **CORS Policy**: Restricted to allowed origins
- **Session Security**: Secure HTTP-only cookies

### ‚ö° **Performance Features**
- **Celery + Redis**: Background task processing
- **Async Operations**: Non-blocking file uploads
- **Connection Pooling**: Efficient database connections
- **Caching Strategy**: Query and session caching
- **Load Balancing**: Ready for horizontal scaling

### üì° **Task Processing Queues**
- **file_processing**: Excel/CSV upload processing
- **query_processing**: Natural language SQL queries  
- **maintenance**: Cleanup and health checks
- **default**: General background tasks

## üèóÔ∏è Project Structure

```
sql_agent_project_v4_multitenant/
‚îú‚îÄ‚îÄ README.md                    # üìö Project documentation
‚îú‚îÄ‚îÄ requirements.txt             # üêç Python dependencies  
‚îú‚îÄ‚îÄ settings.py                 # ‚öôÔ∏è Configuration (pydantic-settings)
‚îú‚îÄ‚îÄ .env                        # üîí Environment variables (not in git)
‚îú‚îÄ‚îÄ .env.example               # üìù Environment template
‚îú‚îÄ‚îÄ .gitignore                 # üö´ Git ignore rules
‚îú‚îÄ‚îÄ docker-compose.yml         # üê≥ Redis container config
‚îÇ
‚îú‚îÄ‚îÄ multitenant_api.py         # üñ•Ô∏è Main FastAPI app & SQL agent
‚îú‚îÄ‚îÄ auth_endpoints.py          # üîë Authentication endpoints
‚îú‚îÄ‚îÄ auth_service.py            # üõ°Ô∏è Authentication service
‚îú‚îÄ‚îÄ user_service.py            # üë• User and session management
‚îú‚îÄ‚îÄ multi_sheet_uploader.py    # üìÅ Excel/CSV upload processing
‚îÇ
‚îú‚îÄ‚îÄ celery_config.py           # üåø Celery configuration
‚îú‚îÄ‚îÄ celery_tasks.py            # ‚ö° Background task definitions
‚îú‚îÄ‚îÄ schema_dependencies.py     # üóÑÔ∏è Schema-per-tenant dependencies
‚îú‚îÄ‚îÄ data_migration.py          # üîÑ Database migration utilities
‚îú‚îÄ‚îÄ initialize_schema_per_tenant.py # üèó Schema initialization
‚îÇ
‚îú‚îÄ‚îÄ start_production.py        # üöÄ Production deployment
‚îú‚îÄ‚îÄ start_multitenant.py       # üõ†Ô∏è Development startup
‚îú‚îÄ‚îÄ start_celery_worker.py     # ‚ö° Worker startup
‚îú‚îÄ‚îÄ start_celery_beat.py       # ‚è∞ Scheduler startup
‚îú‚îÄ‚îÄ start_celery_flower.py     # üå∏ Monitoring dashboard
‚îú‚îÄ‚îÄ start_multi_agent_server.py # ü§ñ Multi-agent system startup
‚îÇ
‚îú‚îÄ‚îÄ agents/                     # ü§ñ Multi-Agent System
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # üì¶ Agent exports
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py          # üèó Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ agent_configs.py       # ‚öôÔ∏è Agent configuration & prompts
‚îÇ   ‚îú‚îÄ‚îÄ sql_agent_wrapper.py   # üìä SQL agent integration
‚îÇ   ‚îú‚îÄ‚îÄ mutual_fund_expert.py  # üí∞ Financial expert agent
‚îÇ   ‚îú‚îÄ‚îÄ web_agent.py           # üåê Web research agent
‚îÇ   ‚îú‚îÄ‚îÄ data_formatter.py      # üìà Data visualization agent
‚îÇ   ‚îî‚îÄ‚îÄ multi_agent_orchestrator.py # üé≠ Main orchestrator
‚îÇ

‚îú‚îÄ‚îÄ services/                   # üîß Service Layer
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # üì¶ Service exports
‚îÇ   ‚îî‚îÄ‚îÄ multi_agent_service.py # üè¢ Business logic layer
‚îÇ
‚îú‚îÄ‚îÄ frontend/                  # ‚öôÔ∏è Next.js 15 + TypeScript + Tailwind
‚îÇ   ‚îú‚îÄ‚îÄ package.json          # üì¶ Node.js dependencies
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.js    # üé® Tailwind CSS config
‚îÇ   ‚îú‚îÄ‚îÄ next.config.js        # ‚ö° Next.js configuration
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx        # üè† Root layout (Gemini-style)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx          # üè† Main chat interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css       # üé® Global styles
‚îÇ   ‚îî‚îÄ‚îÄ components/           # ‚öôÔ∏è Reusable React components
‚îÇ
‚îî‚îÄ‚îÄ venv/                     # üêç Python virtual environment
```

### üîß **Core Components**

**üî• Backend Architecture:**
- **multitenant_api.py**: FastAPI server with SQL agent integration
- **celery_tasks.py**: Background processing (file uploads, queries)
- **schema_dependencies.py**: Smart database routing & multi-tenant logic
- **auth_service.py**: Google OAuth + JWT authentication
- **multi_sheet_uploader.py**: Excel/CSV processing with pandas

**üé® Frontend Architecture:**
- **Next.js 15**: React 18+ with TypeScript
- **Tailwind CSS**: Modern utility-first styling
- **Gemini-style UI**: Chat interface with sidebar navigation
- **Real-time Updates**: WebSocket-like task progress tracking

**üì° Task Processing:**
- **Celery + Redis**: Production-ready async task queue
- **Flower Dashboard**: Task monitoring and debugging
- **Queue Management**: Separate queues for different task types

**ü§ñ Multi-Agent Intelligence System:**
- **MultiAgentOrchestrator**: Main coordinator with dynamic workflow selection
- **SQLAgentWrapper**: Database query specialist with multi-tenant support
- **MutualFundExpertAgent**: Indian financial analysis expert with investment insights
- **WebAgent**: Market research specialist with web data gathering
- **DataFormatterAgent**: Visualization expert creating charts and professional reports
- **MultiAgentService**: Business logic layer with session management and caching
- **Configuration System**: Environment-driven feature toggles and agent parameters

### üß† **Agent Capabilities & Specializations**

**üé≠ MultiAgentOrchestrator (Main Coordinator)**
- Analyzes query complexity and routes to appropriate specialists
- Coordinates multi-agent workflows and manages conversation flow
- Provides intelligent fallback and error recovery
- Maintains session context and conversation history
- Supports 5 workflow types: simple_query, full_analysis_with_web, comparison_analysis, portfolio_analysis, performance_analysis

**üìä SQLAgentWrapper (Database Specialist)**
- Integrates with existing SQL agent infrastructure
- Multi-database discovery and intelligent context switching
- Schema-per-tenant architecture with user isolation
- Advanced query optimization and result caching
- Support for 4+ databases with dynamic discovery

**üí∞ MutualFundExpertAgent (Financial Analyst)**
- Specialized in Indian mutual fund market analysis
- Investment recommendations with risk assessment
- Performance analysis with benchmark comparisons
- Portfolio optimization suggestions
- Regulatory compliance and tax implications

**üåê WebAgent (Market Research Specialist)**
- Real-time market data integration (simulated for demo)
- News sentiment analysis and market trends
- Competitor analysis and industry insights
- Economic indicators and regulatory updates
- Trusted financial news sources integration

**üìà DataFormatterAgent (Visualization Expert)**
- Professional report generation with charts and graphs
- Interactive data visualizations using modern chart libraries
- Executive summary creation with key insights
- Multi-format output (JSON, HTML, PDF-ready)
- Responsive design for web and mobile consumption

### üîÑ **Multi-Agent Workflow Examples**

**Scenario 1: Simple Query**
```
User: "Show me HDFC Top 100 fund performance"
‚Üí Orchestrator ‚Üí SQLAgent ‚Üí DataFormatter ‚Üí Response
```

**Scenario 2: Comprehensive Analysis**
```
User: "Should I invest in large cap funds now?"
‚Üí Orchestrator ‚Üí SQLAgent (fund data) ‚Üí WebAgent (market trends) 
‚Üí MutualFundExpert (analysis) ‚Üí DataFormatter (report) ‚Üí Response
```

**Scenario 3: Comparison Analysis**
```
User: "Compare top 5 ELSS funds"
‚Üí Orchestrator ‚Üí SQLAgent (fund data) ‚Üí MutualFundExpert (comparison)
‚Üí WebAgent (current market) ‚Üí DataFormatter (comparison charts) ‚Üí Response
```

## üìö API Documentation

### ü§ñ **Multi-Agent System API Endpoints**

**Base URL**: `http://localhost:8001/multi-agent`

#### üöÄ **Primary Endpoints**

**1. Process Query**
```http
POST /multi-agent/query
Content-Type: application/json

{
  "query": "What are the top performing large cap mutual funds?",
  "user_email": "user@example.com",
  "enable_caching": true,
  "context": "investment_analysis"
}
```

**Response:**
```json
{
  "response": "Comprehensive analysis with charts and recommendations",
  "workflow_used": "full_analysis_with_web",
  "agents_involved": ["SQLAgent", "MutualFundExpert", "WebAgent", "DataFormatter"],
  "execution_time": "12.5s",
  "cache_hit": false,
  "session_id": "session_abc123"
}
```

**2. Streaming Query (Real-time Updates)**
```http
POST /multi-agent/query/stream
Content-Type: application/json

{
  "query": "Compare HDFC Top 100 and ICICI Prudential Bluechip funds",
  "user_email": "user@example.com"
}
```

**Streaming Response:**
```json
{"type": "status", "message": "Starting analysis..."}
{"type": "agent_start", "agent": "SQLAgent", "task": "Fetching fund data"}
{"type": "agent_progress", "agent": "SQLAgent", "progress": 50}
{"type": "agent_complete", "agent": "SQLAgent", "result": "Fund data retrieved"}
{"type": "final_response", "response": "Detailed comparison analysis..."}
```

#### üîç **System Management Endpoints**

**3. Health Check**
```http
GET /multi-agent/health
```

**Response:**
```json
{
  "status": "healthy",
  "agents": {
    "orchestrator": {"status": "healthy", "last_used": "2024-01-15T10:30:00Z"},
    "sql_agent": {"status": "healthy", "databases_connected": 4},
    "mutual_fund_expert": {"status": "healthy", "specialization": "indian_markets"},
    "web_agent": {"status": "healthy", "sources_available": 5},
    "data_formatter": {"status": "healthy", "chart_engine": "ready"}
  },
  "system_stats": {
    "total_queries_processed": 1247,
    "average_response_time": "8.2s",
    "cache_hit_rate": "73%"
  }
}
```

**4. Available Workflows**
```http
GET /multi-agent/workflows
```

**Response:**
```json
{
  "workflows": [
    {
      "name": "simple_query",
      "description": "Direct SQL queries with intelligent formatting",
      "agents": ["SQLAgent", "DataFormatter"],
      "avg_time": "3.5s"
    },
    {
      "name": "full_analysis_with_web",
      "description": "Comprehensive analysis with market research",
      "agents": ["SQLAgent", "WebAgent", "MutualFundExpert", "DataFormatter"],
      "avg_time": "15.2s"
    }
  ]
}
```

**5. Agent Management**
```http
POST /multi-agent/agents/refresh/{user_email}
```

**Response:**
```json
{
  "message": "Agents refreshed successfully",
  "user_email": "user@example.com",
  "agents_refreshed": 5,
  "cache_cleared": true
}
```

**6. System Configuration**
```http
GET /multi-agent/config
```

**Response:**
```json
{
  "model": "gpt-4o",
  "max_iterations": 10,
  "timeout_seconds": 300,
  "features": {
    "web_research": true,
    "chart_generation": true,
    "caching": true,
    "mutual_fund_expert": true
  },
  "database_count": 4
}
```

**7. Test System**
```http
POST /multi-agent/test
```

**Response:**
```json
{
  "test_results": {
    "orchestrator": "pass",
    "sql_agent": "pass",
    "mutual_fund_expert": "pass",
    "web_agent": "pass",
    "data_formatter": "pass"
  },
  "overall_status": "all_tests_passed",
  "test_duration": "2.3s"
}
```

### üìä **Traditional SQL Agent Endpoints**

**Base URL**: `http://localhost:8001`

- `POST /chat` - Traditional SQL agent chat
- `POST /upload` - File upload and processing
- `GET /discovery/databases` - Database discovery info
- `GET /discovery/summary` - Agent status and database summary
- `POST /agent/refresh` - Refresh SQL agent
- `GET /agent/contexts` - Available database contexts
- `GET /health` - System health check

### üîê **Authentication**

All endpoints require valid JWT authentication:

```http
Authorization: Bearer <jwt_token>
```

Obtain tokens via Google OAuth:
```http
POST /auth/google
```

### üìä **Error Handling**

**Standard Error Response:**
```json
{
  "error": "ValidationError",
  "message": "Invalid query format",
  "details": {
    "field": "query",
    "issue": "Query cannot be empty"
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**HTTP Status Codes:**
- `200` - Success
- `400` - Bad Request (validation errors)
- `401` - Unauthorized (invalid/missing token)
- `403` - Forbidden (insufficient permissions)
- `429` - Rate Limited
- `500` - Internal Server Error
- `503` - Service Unavailable (agents down)

## üõ†Ô∏è Development Guide

### üéÜ **Adding New Features**

**1. New API Endpoints:**
```python
# In multitenant_api.py
@app.post("/your-endpoint")
async def your_endpoint(request: YourRequest, current_user: dict = Depends(get_current_user)):
    # Your logic here
    return {"result": "success"}
```

**2. Background Tasks:**
```python
# In celery_tasks.py
@celery_app.task(bind=True)
def your_background_task(self, data):
    # Long-running task logic
    return {"status": "completed"}
```

**3. Frontend Components:**
```typescript
// In frontend/components/YourComponent.tsx
export function YourComponent() {
  return <div className="p-4 bg-white rounded-lg">Your content</div>
}
```

### üìù **Testing & Validation**

**API Testing:**
```bash
# Health check
curl http://localhost:8001/health

# Authentication test
curl -H "Authorization: Bearer YOUR_JWT_TOKEN" http://localhost:8001/auth/me

# Upload test (with file)
curl -X POST -F "files=@test.xlsx" -H "Authorization: Bearer TOKEN" http://localhost:8001/upload-files
```

**Database Validation:**
```bash
# Initialize schema-per-tenant
python initialize_schema_per_tenant.py

# Run migration script
python data_migration.py

# Check migration status
curl -H "Authorization: Bearer TOKEN" http://localhost:8001/migration/status
```

### üîç **Debugging & Troubleshooting**

**Common Issues & Solutions:**

üêõ **"401 Unauthorized" errors**
```bash
# Solution: Refresh browser to get new JWT token (8-hour expiry)
# Check token status
curl -H "Authorization: Bearer YOUR_TOKEN" http://localhost:8001/auth/me
```

üêõ **File upload processing fails**
```bash
# Solution: Restart Celery workers
python start_celery_worker.py

# Check task status
curl http://localhost:8001/task-status/YOUR_TASK_ID
```

üêõ **Celery worker not starting**
```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Check Redis connection
redis-cli ping

# Restart Redis via Docker
docker-compose restart redis
```

üêõ **Database connection errors**
```bash
# Verify PostgreSQL is running
pg_isready -h localhost -p 5432

# Check database exists
psql -U your_user -l | grep portfoliosql

# Initialize schema if needed
python initialize_schema_per_tenant.py
```

**Monitoring & Logs:**
- **API Logs**: Console output from FastAPI server
- **Celery Logs**: Worker output shows task processing
- **Frontend Logs**: Browser DevTools Console
- **Task Monitoring**: http://localhost:5555 (Flower dashboard)
- **Database Logs**: Enable query logging in PostgreSQL

## üîí Security & Best Practices

### üõ°Ô∏è **Data Protection**
- **Multi-Tenant Isolation**: Schema-per-tenant with proper access controls
- **JWT Security**: 8-hour token expiry with secure HTTP-only cookies
- **Input Sanitization**: SQL injection prevention via parameterized queries
- **File Validation**: Comprehensive Excel/CSV upload validation
- **User Data Isolation**: Each tenant's data completely isolated

### üîê **Environment Security**
- **Secret Management**: All credentials in environment variables
- **Database Security**: Connection pooling with proper authentication
- **CORS Policy**: Restricted to allowed frontend origins
- **Google OAuth**: Secure third-party authentication flow
- **API Rate Limiting**: Built-in FastAPI security features

### üìä **Performance & Monitoring**
- **Async Processing**: Non-blocking file uploads and queries
- **Connection Pooling**: Efficient database connection management
- **Task Queues**: Separate queues for different operation types
- **Monitoring Dashboard**: Real-time task and system monitoring
- **Error Tracking**: Comprehensive logging and error reporting

## üöÄ Production Deployment

### üèóÔ∏è **Production Setup**

**1. Environment Configuration:**
```bash
# Production environment variables
export DEBUG=false
export API_HOST=0.0.0.0
export API_PORT=8001
export JWT_ACCESS_TOKEN_EXPIRE_MINUTES=480
export ENABLE_SCHEMA_PER_TENANT=true
export ENABLE_AUTO_MIGRATION=true

# Database URLs for production
export DATABASE_URL="postgresql://user:pass@prod-db:5432/portfoliosql"
export PORTFOLIOSQL_DATABASE_URI="postgresql://user:pass@prod-db:5432/portfoliosql"

# Redis configuration
export REDIS_URL="redis://prod-redis:6379/0"
export CELERY_BROKER_URL="redis://prod-redis:6379/0"

# Multi-Agent System Configuration
export OPENAI_API_KEY="your_production_openai_key"
export AGENT_MODEL="gpt-4o"
export AGENT_TEMPERATURE="0.3"
export MAX_AGENT_ITERATIONS="10"
export AGENT_TIMEOUT_SECONDS="300"
export ENABLE_AGENT_CACHING="true"
export ENABLE_WEB_RESEARCH="true"
export ENABLE_CHART_GENERATION="true"
export MUTUAL_FUND_EXPERT_ENABLED="true"
export CELERY_RESULT_BACKEND="redis://prod-redis:6379/0"
```

**2. Production Deployment:**
```bash
# All-in-one production startup
python start_production.py

# Or with process manager
pm2 start start_production.py --name "sql-agent-prod"

# Monitor processes
pm2 monit
```

**3. Docker Deployment:**
```bash
# Start Redis container
docker-compose up -d redis

# Build and run application
docker build -t sql-agent .
docker run -d --name sql-agent-app -p 8001:8001 sql-agent
```

## ü§ñ Multi-Agent System Production Integration

### üèóÔ∏è **Multi-Agent Production Setup**

**1. OpenAI API Key Verification:**
```bash
# Verify API key works in production
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{"model": "gpt-4o", "messages": [{"role": "user", "content": "test"}], "max_tokens": 10}' \
     https://api.openai.com/v1/chat/completions
```

**2. Multi-Agent System Health Check:**
```bash
# Start multi-agent enabled server
python start_multi_agent_server.py

# Verify all 5 agents are healthy
curl http://localhost:8001/multi-agent/health | jq '.agents'

# Test system functionality
curl -X POST http://localhost:8001/multi-agent/test \
     -H "Content-Type: application/json"
```

**3. Performance Tuning for Production:**
```bash
# Production optimized settings
export MAX_AGENT_ITERATIONS=15
export AGENT_TIMEOUT_SECONDS=600  
export ENABLE_AGENT_CACHING=true
export WEB_SCRAPING_TIMEOUT=45
export MAX_CHART_DATA_POINTS=500
```

### üìä **Multi-Agent Monitoring**

**Real-time System Monitoring:**
```bash
# Monitor agent performance
while true; do
  echo "=== Multi-Agent Health $(date) ==="
  curl -s http://localhost:8001/multi-agent/health | jq '.system_stats'
  sleep 30
done
```

**Agent Status Dashboard:**
```bash
# Get detailed agent status
curl http://localhost:8001/multi-agent/agents/status | jq '{
  orchestrator: .orchestrator.status,
  sql_agent: .sql_agent.databases_connected,
  expert_agent: .mutual_fund_expert.specialization,
  web_agent: .web_agent.sources_available,
  formatter: .data_formatter.chart_engine
}'
```

### üîß **Multi-Agent Troubleshooting**

**Common Production Issues:**

üêõ **Agent timeout errors:**
```bash
# Increase timeout and check OpenAI API
export AGENT_TIMEOUT_SECONDS=600
curl -I https://api.openai.com/v1/models
```

üêõ **SQLAgent connection issues:**
```bash
# Refresh SQL agent cache
curl -X POST http://localhost:8001/multi-agent/agents/refresh/user@example.com

# Verify database discovery
curl http://localhost:8001/discovery/summary
```

üêõ **High memory usage:**
```bash
# Clear all agent caches
curl -X POST http://localhost:8001/multi-agent/agents/refresh/all

# Monitor memory usage
ps aux | grep python | grep multi_agent
```

### üìà **Scaling & Performance**
- **Horizontal Scaling**: Add more Celery workers across machines
- **Database Scaling**: PostgreSQL read replicas for query performance
- **Load Balancing**: Multiple FastAPI instances behind load balancer
- **Caching**: Redis for session and query result caching
- **CDN**: Static asset delivery for frontend

## üéÜ Features & Roadmap

### ‚úÖ **Current Features**
- üìÅ **Multi-format Upload**: Excel, CSV with multi-sheet support
- ü§ñ **AI-Powered Queries**: Natural language to SQL conversion
- üë• **Multi-Tenant Architecture**: Secure data isolation
- üîÑ **Zero-Downtime Migration**: Database architecture migration
- üé® **Modern UI**: Gemini-style chat interface
- üîë **Google OAuth**: Secure authentication
- ‚ö° **Background Processing**: Async file processing
- üìà **Task Monitoring**: Real-time progress tracking
- üì± **Responsive Design**: Mobile-friendly interface

### üîÆ **Future Enhancements**

**ü§ñ Multi-Agent System Evolution:**
- üåê **Real Web Integration**: Live market data APIs (BSE, NSE, Morningstar)
- üìà **Advanced Visualizations**: Interactive charts with Plotly/D3.js
- üß† **Custom Agent Creation**: User-defined specialist agents
- üîÑ **Workflow Designer**: Visual workflow builder interface
- üìä **Portfolio Management**: Complete portfolio tracking and optimization
- üö® **Smart Alerts**: AI-powered investment opportunity notifications

**üèóÔ∏è System Enhancements:**
- üìä **Advanced Analytics**: Multi-dimensional data analysis
- üé® **Dashboard Builder**: Custom dashboard creation
- üîÑ **API Integrations**: Connect external financial data sources
- üì± **Mobile App**: Native mobile application with agent chat
- üåç **Multi-Language**: Internationalization support
- üîç **Voice Interface**: Voice-to-query conversion

## üîß Extending the Multi-Agent System

### üéÜ **Adding New Agents**

**1. Create New Agent Class:**
```python
# agents/your_custom_agent.py
from agents.base_agent import BaseAgent
from agents.agent_configs import AgentMessage, AgentState

class YourCustomAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(
            agent_id="your_custom_agent",
            agent_type="specialist",
            description="Your agent description",
            config=config
        )
    
    async def process_message(self, message: AgentMessage, state: AgentState) -> AgentMessage:
        # Your custom agent logic here
        prompt = f"As a [your specialty] expert, {message.content}"
        response = await self.call_llm(prompt, message.context)
        
        return AgentMessage(
            content=response,
            agent_id=self.agent_id,
            message_type="response",
            context=message.context
        )
```

**2. Register Agent in Orchestrator:**
```python
# agents/multi_agent_orchestrator.py
# Add to __init__ method:
self.your_custom_agent = YourCustomAgent(self.config)

# Add to _route_to_agents method:
if "your_specialty_keyword" in query.lower():
    agents_to_use.append("your_custom_agent")
```

**3. Add Agent Configuration:**
```python
# settings.py - Add any new configuration variables
YOUR_CUSTOM_AGENT_ENABLED = get_bool_env("YOUR_CUSTOM_AGENT_ENABLED", True)

# agent_prompts.py - Add custom prompts
YOUR_CUSTOM_AGENT_PROMPT = """
You are a specialist in [your domain]. 
Provide expert analysis and recommendations.
"""
```

### üîÑ **Adding New Workflows**

**1. Define Workflow in Orchestrator:**
```python
# agents/multi_agent_orchestrator.py
async def your_custom_workflow(self, query: str, user_email: str, context: dict) -> dict:
    """
    Custom workflow for specific use cases
    """
    workflow_steps = [
        ("your_custom_agent", "Analyze the request"),
        ("sql_agent", "Fetch relevant data"),
        ("data_formatter", "Format results")
    ]
    
    # Execute workflow steps
    results = {}
    for agent_name, task in workflow_steps:
        agent = getattr(self, agent_name)
        result = await agent.process_message(AgentMessage(
            content=f"{task}: {query}",
            context=context
        ), self.state)
        results[agent_name] = result
    
    return self._combine_agent_results(results)
```

**2. Add Workflow to Router:**
```python
# Add to _select_workflow method:
if "custom_analysis" in query.lower():
    return "your_custom_workflow"
```

### üìä **Custom Data Sources Integration**

**1. External API Integration:**
```python
# agents/external_data_agent.py
class ExternalDataAgent(BaseAgent):
    async def fetch_market_data(self, symbol: str):
        # Integration with external APIs
        api_key = self.config.external_api_key
        url = f"https://api.example.com/data/{symbol}"
        
        async with httpx.AsyncClient() as client:
            response = await client.get(url, headers={"API-Key": api_key})
            return response.json()
```

**2. Database Integration:**
```python
# Add new database connections
class CustomDatabaseAgent(BaseAgent):
    async def connect_external_db(self):
        connection_string = self.config.external_db_url
        # Connect to external financial database
        return create_engine(connection_string)
```

### üåê **Production Deployment Extensions**

**1. Kubernetes Deployment:**
```yaml
# k8s/multi-agent-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-agent-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: multi-agent
  template:
    spec:
      containers:
      - name: multi-agent
        image: your-registry/multi-agent:latest
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
```

**2. Advanced Monitoring:**
```python
# monitoring/agent_metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Custom metrics for multi-agent system
agent_requests_total = Counter('agent_requests_total', 'Total agent requests', ['agent_name'])
agent_response_time = Histogram('agent_response_seconds', 'Agent response time')
active_sessions = Gauge('active_agent_sessions', 'Number of active agent sessions')
```

---

## üìù **Support & Documentation**

**üìö Core Documentation:**
- **Complete Guide**: This README.md (comprehensive system overview)
- **API Documentation**: http://localhost:8001/docs (Interactive Swagger UI)
- **API Reference**: http://localhost:8001/redoc (ReDoc format)
- **Task Monitor**: http://localhost:5555 (Flower dashboard)

**ü§ñ Multi-Agent System Documentation:**
- **System Health**: http://localhost:8001/multi-agent/health
- **Available Workflows**: http://localhost:8001/multi-agent/workflows
- **System Configuration**: http://localhost:8001/multi-agent/config
- **Agent Status**: http://localhost:8001/multi-agent/agents/status
- **Real-time Testing**: http://localhost:8001/multi-agent/test

**üîç Development Resources:**
- **Database Discovery**: http://localhost:8001/discovery/summary
- **SQL Agent Status**: http://localhost:8001/health
- **Authentication**: http://localhost:8001/auth/me

**üêõ Support Channels:**
- **Issue Tracking**: Report bugs via GitHub issues
- **Feature Requests**: Suggest enhancements via GitHub discussions
- **System Logs**: Check console output for debugging
- **Performance Monitoring**: Use built-in health check endpoints

**Built with ‚ù§Ô∏è using cutting-edge AI technology**

**Powered by:** OpenAI GPT-4o | FastAPI | Next.js | PostgreSQL | Multi-Agent Intelligence

### Scaling Considerations
- **Database**: Use connection pooling and read replicas
- **Task Queue**: Scale RabbitMQ workers horizontally
- **Frontend**: Deploy to CDN for static assets
- **API**: Use load balancer for multiple backend instances

## üîß Troubleshooting

### Common Issues

**Database Connection Errors**:
```bash
# Check database connectivity
psql -h localhost -U your_user -d portfoliosql
```

**File Upload Failures**:
- Check file size limits
- Verify file format compatibility
- Monitor RabbitMQ worker logs

**Query Errors**:
- Verify database schema
- Check user permissions
- Review SQL generation logs

**Frontend Issues**:
```bash
# Clear cache and reinstall
cd frontend
rm -rf node_modules package-lock.json
npm install
npm run dev
```

### Performance Issues
- Monitor database query performance
- Check RabbitMQ queue status
- Review memory usage of workers
- Optimize database indexes

### Getting Help
- Check API documentation at `/docs`
- Review application logs
- Verify environment configuration
- Test with minimal examples

## üìà Performance Metrics

### Benchmarks
- **File Upload**: ~1MB/second processing rate
- **Query Response**: <2 seconds for complex queries
- **Concurrent Users**: Tested with 50+ simultaneous users
- **Database Operations**: Optimized for <100ms response time

### Monitoring
- **API Metrics**: Built-in FastAPI metrics
- **Database Performance**: Query execution time logging
- **Task Queue**: RabbitMQ management interface
- **Resource Usage**: Memory and CPU monitoring

## ü§ù Contributing

### Development Workflow
1. Fork the repository
2. Create feature branch
3. Implement changes with tests
4. Update documentation
5. Submit pull request

### Code Standards
- **Python**: Follow PEP 8 guidelines
- **TypeScript**: Use strict type checking
- **SQL**: Use parameterized queries
- **Documentation**: Update README for new features

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè Acknowledgments

- OpenAI for GPT integration
- FastAPI team for the excellent framework
- Next.js team for the frontend framework
- PostgreSQL community for the robust database
- RabbitMQ team for the message queue system

---

**Version**: 4.0  
**Last Updated**: 2025-06-26  
**Maintained By**: Development Team
