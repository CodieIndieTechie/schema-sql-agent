# ğŸš€ Multi-Agent Financial Analysis System

> A production-ready, AI-powered multi-agent system with advanced SQL capabilities, featuring natural language querying, intelligent financial analysis, multi-database discovery, file upload processing, and modern Gemini-style UI.

## âœ¨ Overview

This sophisticated multi-agent financial analysis system combines the power of specialized AI agents to provide comprehensive financial insights. Built on a robust multi-tenant SQL foundation, it enables users to query databases using natural language, get expert financial analysis, research current market data, and receive beautifully formatted reports - all through an intelligent multi-agent orchestration system.

### ğŸ¯ **What Makes This Special:**
- **Multi-Agent Intelligence**: 5 specialized agents working together for comprehensive analysis
- **Financial Expertise**: Dedicated mutual fund and investment analysis capabilities
- **Dynamic Database Discovery**: Automatically discovers and maps multiple databases
- **Schema-per-Tenant**: Enterprise-grade multi-tenant architecture with data isolation
- **Real-Time Processing**: Streaming updates and real-time agent coordination
- **Production Ready**: Modular, configurable, and extensible architecture

## ğŸ¤– Multi-Agent System Features

### ğŸ† **Intelligent Agent Orchestration**
- **OrchestratorAgent**: Main coordinator that analyzes queries and routes to appropriate agents
- **Dynamic Workflow Selection**: Automatically chooses between 5+ workflow types based on query complexity
- **Real-Time Coordination**: Agents communicate and collaborate in real-time
- **Intelligent Routing**: Smart decision-making on which agents to involve
- **Session Management**: Maintains conversation context across multi-turn interactions

### ğŸ“Š **Specialized Financial Agents**
- **SQLAgentWrapper**: Enhanced integration with existing multi-database SQL infrastructure
- **MutualFundExpertAgent**: Dedicated Indian mutual fund analysis with investment insights
- **WebAgent**: Current market research and financial news gathering
- **DataFormatterAgent**: Beautiful chart generation and professional report formatting
- **Expert Analysis**: Deep financial insights with context-aware recommendations

### ğŸ”„ **Advanced Workflow Management**
- **Simple Query**: Direct SQL queries with intelligent formatting
- **Full Analysis with Web**: Comprehensive analysis combining database + market research
- **Comparison Analysis**: Side-by-side fund/investment comparisons
- **Portfolio Analysis**: Portfolio-level insights and recommendations
- **Performance Analysis**: Detailed performance analysis with benchmarking

### ğŸŒ **Multi-Agent API Endpoints**
- `POST /multi-agent/query` - Process queries through multi-agent system
- `POST /multi-agent/query/stream` - Real-time streaming updates
- `GET /multi-agent/health` - Comprehensive system health monitoring
- `GET /multi-agent/workflows` - Available workflows and capabilities
- `POST /multi-agent/agents/refresh/{user_email}` - Agent cache management
- `GET /multi-agent/agents/status` - Detailed agent status and statistics
- `GET /multi-agent/config` - System configuration and feature toggles

### âš™ï¸ **Configuration & Customization**
- **Environment-Based Configuration**: Easy tuning without code changes
- **Feature Toggles**: Enable/disable agents and capabilities
- **Timeout & Iteration Control**: Configurable safety limits
- **Model Selection**: Choose between different AI models
- **Expert Prompts**: Editable agent prompts and behaviors

## ğŸ¯ Traditional SQL Agent Features

### ğŸ¢ **Multi-Tenant Architecture**
- **Schema-per-Tenant**: Advanced multi-tenant isolation with dedicated database schemas
- **Database-per-Tenant**: Backward compatibility with legacy user databases
- **Smart Migration**: Automatic migration between architectures with zero downtime
- **Session Management**: Secure JWT-based authentication with Google OAuth
- **Feature Flags**: Gradual rollout capabilities for new features

### ğŸ¤– **AI-Powered SQL Generation**
- **Natural Language Processing**: Ask questions in plain English, get SQL results
- **Intelligent Database Routing**: Automatically determines which database/schema to query
- **Context-Aware Responses**: Understands data relationships and provides meaningful insights
- **Advanced Query Optimization**: Generates efficient SQL with proper joins and filters
- **Error Handling**: Intelligent error recovery and query refinement

### ğŸ“ **File Upload & Processing**
- **Multi-Format Support**: Excel (.xlsx, .xls) and CSV files
- **Multi-Sheet Processing**: Handles Excel files with multiple sheets automatically
- **Asynchronous Processing**: Celery-based background processing with Redis
- **Real-time Status**: WebSocket-like updates on upload progress
- **Data Validation**: Comprehensive validation and error handling
- **Schema Detection**: Automatic data type inference and table creation

### ğŸ¨ **Modern Gemini-Style UI**
- **Clean Interface**: Google Gemini-inspired design with collapsible sidebar
- **Responsive Design**: Mobile-first approach with Tailwind CSS
- **Real-time Chat**: Modern chat interface with message history
- **File Management**: Integrated file upload with attachment preview
- **Data Preview**: Right sidebar showing database table contents
- **Authentication**: Seamless Google OAuth integration

### ğŸ—ï¸ **Production-Ready Architecture**
- **FastAPI Backend**: High-performance async API with automatic OpenAPI docs
- **Next.js Frontend**: Server-side rendering with TypeScript
- **PostgreSQL**: Robust database with multi-tenant support
- **Celery + Redis**: Distributed task processing with monitoring
- **Docker Integration**: Containerized services for easy deployment
- **Monitoring**: Flower dashboard for task monitoring

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[Next.js App<br/>Port: 3001] --> B[Authentication<br/>Google OAuth]
        A --> C[Chat Interface<br/>Gemini Style]
        A --> D[File Upload<br/>Drag & Drop]
    end
    
    subgraph "API Layer"
        E[FastAPI Server<br/>Port: 8001] --> F[JWT Auth<br/>Middleware]
        E --> G[Multi-Agent API<br/>Endpoints]
        E --> H[Traditional SQL<br/>Endpoints]
        E --> I[File Processing<br/>Endpoints]
    end
    
    subgraph "Multi-Agent Intelligence Layer"
        J[MultiAgentOrchestrator<br/>Main Coordinator] --> K[SQLAgentWrapper<br/>Database Queries]
        J --> L[MutualFundExpert<br/>Financial Analysis]
        J --> M[WebAgent<br/>Market Research]
        J --> N[DataFormatter<br/>Visualization]
        O[MultiAgentService<br/>Business Logic] --> J
        P[Configuration<br/>Environment Variables] --> J
    end
    
    subgraph "Task Processing"
        Q[Celery Workers<br/>Background Tasks] --> R[File Processing<br/>Queue]
        Q --> S[Query Processing<br/>Queue]
        Q --> T[Maintenance<br/>Queue]
        U[Redis Broker<br/>Port: 6379] --> Q
        V[Flower Dashboard<br/>Port: 5555] --> Q
    end
    
    subgraph "Database Layer"
        W[PostgreSQL<br/>Multi-tenant]
        X[portfoliosql<br/>Shared Schema]
        Y[user_schema_*<br/>Tenant Schemas]
        Z[user_db_*<br/>Legacy DBs]
        AA[Discovery Service<br/>4+ Databases]
    end
    
    A --> E
    E --> G
    G --> O
    O --> K
    K --> W
    E --> Q
    W --> X
    W --> Y
    W --> Z
    K --> AA
```

### ğŸ—„ï¸ Database Architecture

**Multi-Tenant Database Strategy:**

1. **portfoliosql**: Central database with schema-per-tenant architecture
   - `public` schema: Shared portfolio/financial data
   - `user_schema_{id}`: Individual tenant schemas for uploaded data
   - `tenants` table: Tenant management and mapping
   - `chat_history` table: Persistent chat history storage

2. **user_db_{hash}**: Legacy database-per-tenant (backward compatibility)
   - Individual PostgreSQL databases for existing users
   - Automatic migration to schema-per-tenant available
   - Zero-downtime migration with feature flags

3. **Smart Database Routing**: Intelligent selection between architectures
   - Feature flags control migration rollout
   - Automatic fallback to legacy system
   - Seamless user experience during transition

## ğŸ¤– Multi-Agent System Configuration

### ğŸ“Š **Environment Variables for Multi-Agent System**

```bash
# === OpenAI Configuration ===
OPENAI_API_KEY=your_openai_api_key_here
AGENT_MODEL=gpt-4o
AGENT_TEMPERATURE=0.3
AGENT_MAX_TOKENS=3000

# === Orchestrator Configuration ===
MAX_AGENT_ITERATIONS=10
AGENT_TIMEOUT_SECONDS=300
ENABLE_AGENT_CACHING=true

# === Feature Toggles ===
ENABLE_WEB_RESEARCH=true
WEB_SEARCH_ENABLED=false
ENABLE_CHART_GENERATION=true
MUTUAL_FUND_EXPERT_ENABLED=true

# === Web Agent Configuration ===
WEB_SCRAPING_TIMEOUT=30
MAX_WEB_SOURCES=5

# === Data Formatter Configuration ===
MAX_CHART_DATA_POINTS=100

# === Expert Agent Configuration ===
FINANCIAL_ANALYSIS_DEPTH=comprehensive
```

### ğŸ”§ **Multi-Agent System Usage Examples**

**1. Simple Query Processing:**
```bash
curl -X POST http://localhost:8001/multi-agent/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the top performing large cap mutual funds?",
    "user_email": "user@example.com",
    "enable_caching": true
  }'
```

**2. Streaming Analysis:**
```bash
curl -X POST http://localhost:8001/multi-agent/query/stream \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Compare HDFC Top 100 and ICICI Prudential Bluechip funds",
    "user_email": "user@example.com"
  }'
```

**3. System Health Check:**
```bash
curl -X GET http://localhost:8001/multi-agent/health
```

**4. Available Workflows:**
```bash
curl -X GET http://localhost:8001/multi-agent/workflows
```

### ğŸ” **Multi-Agent Workflow Types**

1. **simple_query**: Direct SQL queries with intelligent formatting
2. **full_analysis_with_web**: Comprehensive analysis with market research
3. **comparison_analysis**: Side-by-side fund/investment comparisons
4. **portfolio_analysis**: Portfolio-level insights and recommendations
5. **performance_analysis**: Detailed performance analysis with benchmarking

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites
- **Python 3.8+** with pip
- **Node.js 18+** with npm
- **PostgreSQL 12+**
- **Redis 6+** (for task processing)
- **Docker** (optional, for Redis)

### âš™ï¸ Environment Setup

**1. Clone and Setup Python Environment:**
```bash
git clone <repository-url>
cd sql_agent_project_v4_multitenant
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

**2. Configure Environment Variables:**
```bash
cp .env.example .env
# Edit .env with your configuration
```

**Required Environment Variables:**
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
LANGCHAIN_API_KEY=your_langchain_api_key  # Optional for tracing

# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/portfoliosql
PORTFOLIOSQL_DATABASE_URI=postgresql://username:password@localhost:5432/portfoliosql
DB_HOST=localhost
DB_PORT=5432
DB_USER=your_db_user
DB_PASSWORD=your_db_password

# API Configuration
API_HOST=0.0.0.0
API_PORT=8001
DEBUG=True

# Security
SECRET_KEY=your_secret_key_here
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=480

# Google OAuth
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Feature Flags
ENABLE_SCHEMA_PER_TENANT=true
ENABLE_AUTO_MIGRATION=true
```

**3. Database Setup:**
```sql
-- Create the central database
CREATE DATABASE portfoliosql;

-- Initialize schema-per-tenant structure
python initialize_schema_per_tenant.py
```

**4. Redis Setup:**
```bash
# Option 1: Using Docker (Recommended)
docker-compose up -d redis

# Option 2: Local Redis installation
# Install Redis locally and start service
```

**5. Frontend Setup:**
```bash
cd frontend
npm install
npm run build
cd ..
```

## ğŸ¬ Running the Application

### ğŸ¤– **Option 1: Multi-Agent System (Recommended)**
```bash
python start_multi_agent_server.py
```
**Starts multi-agent system with:**
- âœ… FastAPI backend with multi-agent endpoints (http://localhost:8001)
- âœ… 5 Specialized AI agents (SQL, Expert, Web, Formatter, Orchestrator)
- âœ… Real-time streaming capabilities
- âœ… Dynamic workflow selection
- âœ… Multi-database discovery (4+ databases)
- âœ… API Documentation: http://localhost:8001/docs
- âœ… Multi-agent health check: http://localhost:8001/multi-agent/health

### ğŸ”¥ **Option 2: Full Production Mode**
```bash
python start_production.py
```
**Starts all services:**
- âœ… Redis broker
- âœ… FastAPI backend (http://localhost:8001)
- âœ… Next.js frontend (http://localhost:3001)
- âœ… Celery workers (background processing)
- âœ… Celery beat (scheduled tasks)
- âœ… Flower dashboard (http://localhost:5555)
- âœ… Multi-agent system integrated

### ğŸ› ï¸ **Option 2: Development Mode**
```bash
python start_multitenant.py
```
**Starts basic services:**
- âœ… FastAPI backend (http://localhost:8001)
- âœ… Next.js frontend (http://localhost:3001)
- âš ï¸ **Note**: Start Celery workers separately for full functionality

### âš¡ **Option 4: Individual Components**
```bash
# Terminal 1: Backend API
python -m uvicorn multitenant_api:app --host 0.0.0.0 --port 8001 --reload

# Terminal 2: Celery Worker (Essential for file uploads)
python start_celery_worker.py

# Terminal 3: Celery Beat (Optional - for maintenance tasks)
python start_celery_beat.py

# Terminal 4: Flower Monitoring (Optional)
python start_celery_flower.py

# Terminal 5: Frontend
cd frontend && npm run dev
```

### ğŸŒ Access Points
- **ğŸ¨ Frontend Application**: http://localhost:3001
- **ğŸ”§ API Documentation**: http://localhost:8001/docs
- **ğŸ“š API Redoc**: http://localhost:8001/redoc
- **ğŸŒ¸ Flower Dashboard**: http://localhost:5555 (admin/password)
- **âš¡ Redis**: localhost:6379

## ğŸ“š API Documentation

### ğŸ”‘ Authentication Endpoints
```http
GET /auth/google/login
# Initiate Google OAuth login flow

GET /auth/google/callback
# Handle Google OAuth callback

GET /auth/me
# Get current user information
Authorization: Bearer {jwt_token}
```

### ğŸ“ File Upload Endpoints
```http
POST /upload-files
# Upload Excel/CSV files for processing
Content-Type: multipart/form-data
Authorization: Bearer {jwt_token}
Body: files[]
```

```http
GET /task-status/{task_id}
# Check background task status
Authorization: Bearer {jwt_token}
```

### ğŸ” Query Endpoints
```http
POST /query
# Natural language database queries
Authorization: Bearer {jwt_token}
Content-Type: application/json
{
  "query": "Show me the top 10 products by sales",
  "session_id": "optional_session_id"
}
```

### ğŸ—„ï¸ User Data Management
```http
GET /user/tables
# List user's uploaded tables
Authorization: Bearer {jwt_token}

GET /user/databases
# List available databases for user
Authorization: Bearer {jwt_token}
```

### ğŸ”„ Migration Endpoints
```http
GET /migration/status
# Check user's migration status
Authorization: Bearer {jwt_token}

POST /migration/trigger
# Manually trigger migration to schema-per-tenant
Authorization: Bearer {jwt_token}
```

### â¤ï¸ Health Check
```http
GET /health
# API health status (no authentication required)
```

### ğŸ“¦ Response Formats

**Successful Query Response:**
```json
{
  "success": true,
  "result": [
    {"product": "Widget A", "sales": 15000},
    {"product": "Widget B", "sales": 12000}
  ],
  "query_used": "SELECT product, sales FROM products ORDER BY sales DESC LIMIT 2",
  "explanation": "Retrieved top products by sales from your uploaded data.",
  "execution_time": 0.043
}
```

**File Upload Task Status:**
```json
{
  "task_id": "60021753-7e6e-4e5c-aee4-39f55eedd934",
  "status": "SUCCESS",
  "progress": 100,
  "message": "File processing completed successfully",
  "result": {
    "tables_created": 6,
    "total_rows": 97,
    "processing_time": 2.34,
    "sheets": ["Products", "Orders", "Customers"]
  }
}
```

**Authentication Response:**
```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
  "token_type": "bearer",
  "expires_in": 28800,
  "user": {
    "id": "user123",
    "email": "user@example.com",
    "name": "John Doe"
  }
}
```

## ğŸ† Usage Examples

### ğŸ”‘ **Authentication Flow**
1. Visit **http://localhost:3001**
2. Click **"Continue with Google"**
3. Complete OAuth flow in popup
4. Automatically redirected to chat interface

### ğŸ“ **File Upload Workflow**
1. **Click attachment button** (ğŸ“) in chat input
2. **Select Excel/CSV files** (supports multi-sheet Excel)
3. **Files upload automatically** with real-time progress
4. **Background processing** creates database tables
5. **Chat confirmation** shows tables created and row counts

### ğŸ’¬ **Chat Interface Usage**

**Query Your Uploaded Data:**
```
ğŸ“‹ "Show me the top 10 products by sales volume"
ğŸ“Š "What's the average order value by customer segment?"
ğŸ“ˆ "Create a summary of monthly revenue trends"
ğŸ¯ "Which customers have the highest lifetime value?"
```

**Query Portfolio/Market Data:**
```
ğŸ’¹ "What tech stocks are performing best this quarter?"
ğŸ’° "Show me dividend-paying stocks with yield > 3%"
ğŸ“‰ "Compare sector performance year-to-date"
ğŸŒ "What are the top emerging market investments?"
```

**Cross-Database Analysis:**
```
ğŸ”„ "How does my business revenue correlate with market trends?"
ğŸ¤ "Compare my sales performance with industry benchmarks"
ğŸ” "Find patterns between my customer data and economic indicators"
```

### ğŸ¨ **Modern UI Features**
- **ğŸ§  Sidebar Navigation**: Hover to expand, shows chat history
- **ğŸ“ Message Bubbles**: Clean Gemini-style conversation flow
- **ğŸ“ File Attachments**: Drag-and-drop or click to upload
- **ğŸ”„ Real-time Updates**: Live progress tracking
- **ğŸ“± Responsive Design**: Works on desktop, tablet, and mobile
- **ğŸŒ™ Dark/Light Theme**: Automatic theme detection

## âš™ï¸ Configuration

### ğŸ—„ï¸ **Database Architecture**
- **Central Database**: `portfoliosql` with schema-per-tenant
- **Legacy Support**: `user_db_{hash}` databases with migration path
- **Smart Routing**: Automatic selection based on feature flags
- **Connection Pooling**: SQLAlchemy with async support

### ğŸ”’ **Security Configuration**
- **JWT Authentication**: 8-hour token expiry
- **Google OAuth**: Secure third-party authentication
- **Environment Variables**: All secrets externalized
- **CORS Policy**: Restricted to allowed origins
- **Session Security**: Secure HTTP-only cookies

### âš¡ **Performance Features**
- **Celery + Redis**: Background task processing
- **Async Operations**: Non-blocking file uploads
- **Connection Pooling**: Efficient database connections
- **Caching Strategy**: Query and session caching
- **Load Balancing**: Ready for horizontal scaling

### ğŸ“¡ **Task Processing Queues**
- **file_processing**: Excel/CSV upload processing
- **query_processing**: Natural language SQL queries  
- **maintenance**: Cleanup and health checks
- **default**: General background tasks

## ğŸ—ï¸ Project Structure

```
sql_agent_project_v4_multitenant/
â”œâ”€â”€ README.md                    # ğŸ“š Project documentation
â”œâ”€â”€ requirements.txt             # ğŸ Python dependencies  
â”œâ”€â”€ settings.py                 # âš™ï¸ Configuration (pydantic-settings)
â”œâ”€â”€ .env                        # ğŸ”’ Environment variables (not in git)
â”œâ”€â”€ .env.example               # ğŸ“ Environment template
â”œâ”€â”€ .gitignore                 # ğŸš« Git ignore rules
â”œâ”€â”€ docker-compose.yml         # ğŸ³ Redis container config
â”‚
â”œâ”€â”€ multitenant_api.py         # ğŸ–¥ï¸ Main FastAPI app & SQL agent
â”œâ”€â”€ auth_endpoints.py          # ğŸ”‘ Authentication endpoints
â”œâ”€â”€ auth_service.py            # ğŸ›¡ï¸ Authentication service
â”œâ”€â”€ user_service.py            # ğŸ‘¥ User and session management
â”œâ”€â”€ multi_sheet_uploader.py    # ğŸ“ Excel/CSV upload processing
â”‚
â”œâ”€â”€ celery_config.py           # ğŸŒ¿ Celery configuration
â”œâ”€â”€ celery_tasks.py            # âš¡ Background task definitions
â”œâ”€â”€ schema_dependencies.py     # ğŸ—„ï¸ Schema-per-tenant dependencies
â”œâ”€â”€ data_migration.py          # ğŸ”„ Database migration utilities
â”œâ”€â”€ initialize_schema_per_tenant.py # ğŸ— Schema initialization
â”‚
â”œâ”€â”€ start_production.py        # ğŸš€ Production deployment
â”œâ”€â”€ start_multitenant.py       # ğŸ› ï¸ Development startup
â”œâ”€â”€ start_celery_worker.py     # âš¡ Worker startup
â”œâ”€â”€ start_celery_beat.py       # â° Scheduler startup
â”œâ”€â”€ start_celery_flower.py     # ğŸŒ¸ Monitoring dashboard
â”œâ”€â”€ start_multi_agent_server.py # ğŸ¤– Multi-agent system startup
â”‚
â”œâ”€â”€ agents/                     # ğŸ¤– Multi-Agent System
â”‚   â”œâ”€â”€ __init__.py            # ğŸ“¦ Agent exports
â”‚   â”œâ”€â”€ base_agent.py          # ğŸ— Abstract base class
â”‚   â”œâ”€â”€ agent_configs.py       # âš™ï¸ Agent configuration & prompts
â”‚   â”œâ”€â”€ sql_agent_wrapper.py   # ğŸ“Š SQL agent integration
â”‚   â”œâ”€â”€ mutual_fund_expert.py  # ğŸ’° Financial expert agent
â”‚   â”œâ”€â”€ web_agent.py           # ğŸŒ Web research agent
â”‚   â”œâ”€â”€ data_formatter.py      # ğŸ“ˆ Data visualization agent
â”‚   â””â”€â”€ multi_agent_orchestrator.py # ğŸ­ Main orchestrator
â”‚

â”œâ”€â”€ services/                   # ğŸ”§ Service Layer
â”‚   â”œâ”€â”€ __init__.py            # ğŸ“¦ Service exports
â”‚   â””â”€â”€ multi_agent_service.py # ğŸ¢ Business logic layer
â”‚
â”œâ”€â”€ frontend/                  # âš™ï¸ Next.js 15 + TypeScript + Tailwind
â”‚   â”œâ”€â”€ package.json          # ğŸ“¦ Node.js dependencies
â”‚   â”œâ”€â”€ tailwind.config.js    # ğŸ¨ Tailwind CSS config
â”‚   â”œâ”€â”€ next.config.js        # âš¡ Next.js configuration
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx        # ğŸ  Root layout (Gemini-style)
â”‚   â”‚   â”œâ”€â”€ page.tsx          # ğŸ  Main chat interface
â”‚   â”‚   â””â”€â”€ globals.css       # ğŸ¨ Global styles
â”‚   â””â”€â”€ components/           # âš™ï¸ Reusable React components
â”‚
â””â”€â”€ venv/                     # ğŸ Python virtual environment
```

### ğŸ”§ **Core Components**

**ğŸ”¥ Backend Architecture:**
- **multitenant_api.py**: FastAPI server with SQL agent integration
- **celery_tasks.py**: Background processing (file uploads, queries)
- **schema_dependencies.py**: Smart database routing & multi-tenant logic
- **auth_service.py**: Google OAuth + JWT authentication
- **multi_sheet_uploader.py**: Excel/CSV processing with pandas

**ğŸ¨ Frontend Architecture:**
- **Next.js 15**: React 18+ with TypeScript
- **Tailwind CSS**: Modern utility-first styling
- **Gemini-style UI**: Chat interface with sidebar navigation
- **Real-time Updates**: WebSocket-like task progress tracking

**ğŸ“¡ Task Processing:**
- **Celery + Redis**: Production-ready async task queue
- **Flower Dashboard**: Task monitoring and debugging
- **Queue Management**: Separate queues for different task types

**ğŸ¤– Multi-Agent Intelligence System:**
- **MultiAgentOrchestrator**: Main coordinator with dynamic workflow selection
- **SQLAgentWrapper**: Database query specialist with multi-tenant support
- **MutualFundExpertAgent**: Indian financial analysis expert with investment insights
- **WebAgent**: Market research specialist with web data gathering
- **DataFormatterAgent**: Visualization expert creating charts and professional reports
- **MultiAgentService**: Business logic layer with session management and caching
- **Configuration System**: Environment-driven feature toggles and agent parameters

### ğŸ§  **Agent Capabilities & Specializations**

**ğŸ­ MultiAgentOrchestrator (Main Coordinator)**
- Analyzes query complexity and routes to appropriate specialists
- Coordinates multi-agent workflows and manages conversation flow
- Provides intelligent fallback and error recovery
- Maintains session context and conversation history
- Supports 5 workflow types: simple_query, full_analysis_with_web, comparison_analysis, portfolio_analysis, performance_analysis

**ğŸ“Š SQLAgentWrapper (Database Specialist)**
- Integrates with existing SQL agent infrastructure
- Multi-database discovery and intelligent context switching
- Schema-per-tenant architecture with user isolation
- Advanced query optimization and result caching
- Support for 4+ databases with dynamic discovery

**ğŸ’° MutualFundExpertAgent (Financial Analyst)**
- Specialized in Indian mutual fund market analysis
- Investment recommendations with risk assessment
- Performance analysis with benchmark comparisons
- Portfolio optimization suggestions
- Regulatory compliance and tax implications

**ğŸŒ WebAgent (Market Research Specialist)**
- Real-time market data integration (simulated for demo)
- News sentiment analysis and market trends
- Competitor analysis and industry insights
- Economic indicators and regulatory updates
- Trusted financial news sources integration

**ğŸ“ˆ DataFormatterAgent (Visualization Expert)**
- Professional report generation with charts and graphs
- Interactive data visualizations using modern chart libraries
- Executive summary creation with key insights
- Multi-format output (JSON, HTML, PDF-ready)
- Responsive design for web and mobile consumption

### ğŸ”„ **Multi-Agent Workflow Examples**

**Scenario 1: Simple Query**
```
User: "Show me HDFC Top 100 fund performance"
â†’ Orchestrator â†’ SQLAgent â†’ DataFormatter â†’ Response
```

**Scenario 2: Comprehensive Analysis**
```
User: "Should I invest in large cap funds now?"
â†’ Orchestrator â†’ SQLAgent (fund data) â†’ WebAgent (market trends) 
â†’ MutualFundExpert (analysis) â†’ DataFormatter (report) â†’ Response
```

**Scenario 3: Comparison Analysis**
```
User: "Compare top 5 ELSS funds"
â†’ Orchestrator â†’ SQLAgent (fund data) â†’ MutualFundExpert (comparison)
â†’ WebAgent (current market) â†’ DataFormatter (comparison charts) â†’ Response
```

## ğŸ“š API Documentation

### ğŸ¤– **Multi-Agent System API Endpoints**

**Base URL**: `http://localhost:8001/multi-agent`

#### ğŸš€ **Primary Endpoints**

**1. Process Query**
```http
POST /multi-agent/query
Content-Type: application/json

{
  "query": "What are the top performing large cap mutual funds?",
  "user_email": "user@example.com",
  "enable_caching": true,
  "context": "investment_analysis"
}
```

**Response:**
```json
{
  "response": "Comprehensive analysis with charts and recommendations",
  "workflow_used": "full_analysis_with_web",
  "agents_involved": ["SQLAgent", "MutualFundExpert", "WebAgent", "DataFormatter"],
  "execution_time": "12.5s",
  "cache_hit": false,
  "session_id": "session_abc123"
}
```

**2. Streaming Query (Real-time Updates)**
```http
POST /multi-agent/query/stream
Content-Type: application/json

{
  "query": "Compare HDFC Top 100 and ICICI Prudential Bluechip funds",
  "user_email": "user@example.com"
}
```

**Streaming Response:**
```json
{"type": "status", "message": "Starting analysis..."}
{"type": "agent_start", "agent": "SQLAgent", "task": "Fetching fund data"}
{"type": "agent_progress", "agent": "SQLAgent", "progress": 50}
{"type": "agent_complete", "agent": "SQLAgent", "result": "Fund data retrieved"}
{"type": "final_response", "response": "Detailed comparison analysis..."}
```

#### ğŸ” **System Management Endpoints**

**3. Health Check**
```http
GET /multi-agent/health
```

**Response:**
```json
{
  "status": "healthy",
  "agents": {
    "orchestrator": {"status": "healthy", "last_used": "2024-01-15T10:30:00Z"},
    "sql_agent": {"status": "healthy", "databases_connected": 4},
    "mutual_fund_expert": {"status": "healthy", "specialization": "indian_markets"},
    "web_agent": {"status": "healthy", "sources_available": 5},
    "data_formatter": {"status": "healthy", "chart_engine": "ready"}
  },
  "system_stats": {
    "total_queries_processed": 1247,
    "average_response_time": "8.2s",
    "cache_hit_rate": "73%"
  }
}
```

**4. Available Workflows**
```http
GET /multi-agent/workflows
```

**Response:**
```json
{
  "workflows": [
    {
      "name": "simple_query",
      "description": "Direct SQL queries with intelligent formatting",
      "agents": ["SQLAgent", "DataFormatter"],
      "avg_time": "3.5s"
    },
    {
      "name": "full_analysis_with_web",
      "description": "Comprehensive analysis with market research",
      "agents": ["SQLAgent", "WebAgent", "MutualFundExpert", "DataFormatter"],
      "avg_time": "15.2s"
    }
  ]
}
```

**5. Agent Management**
```http
POST /multi-agent/agents/refresh/{user_email}
```

**Response:**
```json
{
  "message": "Agents refreshed successfully",
  "user_email": "user@example.com",
  "agents_refreshed": 5,
  "cache_cleared": true
}
```

**6. System Configuration**
```http
GET /multi-agent/config
```

**Response:**
```json
{
  "model": "gpt-4o",
  "max_iterations": 10,
  "timeout_seconds": 300,
  "features": {
    "web_research": true,
    "chart_generation": true,
    "caching": true,
    "mutual_fund_expert": true
  },
  "database_count": 4
}
```

**7. Test System**
```http
POST /multi-agent/test
```

**Response:**
```json
{
  "test_results": {
    "orchestrator": "pass",
    "sql_agent": "pass",
    "mutual_fund_expert": "pass",
    "web_agent": "pass",
    "data_formatter": "pass"
  },
  "overall_status": "all_tests_passed",
  "test_duration": "2.3s"
}
```

### ğŸ“Š **Traditional SQL Agent Endpoints**

**Base URL**: `http://localhost:8001`

- `POST /chat` - Traditional SQL agent chat
- `POST /upload` - File upload and processing
- `GET /discovery/databases` - Database discovery info
- `GET /discovery/summary` - Agent status and database summary
- `POST /agent/refresh` - Refresh SQL agent
- `GET /agent/contexts` - Available database contexts
- `GET /health` - System health check

### ğŸ” **Authentication**

All endpoints require valid JWT authentication:

```http
Authorization: Bearer <jwt_token>
```

Obtain tokens via Google OAuth:
```http
POST /auth/google
```

### ğŸ“Š **Error Handling**

**Standard Error Response:**
```json
{
  "error": "ValidationError",
  "message": "Invalid query format",
  "details": {
    "field": "query",
    "issue": "Query cannot be empty"
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**HTTP Status Codes:**
- `200` - Success
- `400` - Bad Request (validation errors)
- `401` - Unauthorized (invalid/missing token)
- `403` - Forbidden (insufficient permissions)
- `429` - Rate Limited
- `500` - Internal Server Error
- `503` - Service Unavailable (agents down)

## ğŸ› ï¸ Development Guide

### ğŸ† **Adding New Features**

**1. New API Endpoints:**
```python
# In multitenant_api.py
@app.post("/your-endpoint")
async def your_endpoint(request: YourRequest, current_user: dict = Depends(get_current_user)):
    # Your logic here
    return {"result": "success"}
```

**2. Background Tasks:**
```python
# In celery_tasks.py
@celery_app.task(bind=True)
def your_background_task(self, data):
    # Long-running task logic
    return {"status": "completed"}
```

**3. Frontend Components:**
```typescript
// In frontend/components/YourComponent.tsx
export function YourComponent() {
  return <div className="p-4 bg-white rounded-lg">Your content</div>
}
```

### ğŸ“ **Testing & Validation**

**API Testing:**
```bash
# Health check
curl http://localhost:8001/health

# Authentication test
curl -H "Authorization: Bearer YOUR_JWT_TOKEN" http://localhost:8001/auth/me

# Upload test (with file)
curl -X POST -F "files=@test.xlsx" -H "Authorization: Bearer TOKEN" http://localhost:8001/upload-files
```

**Database Validation:**
```bash
# Initialize schema-per-tenant
python initialize_schema_per_tenant.py

# Run migration script
python data_migration.py

# Check migration status
curl -H "Authorization: Bearer TOKEN" http://localhost:8001/migration/status
```

### ğŸ” **Debugging & Troubleshooting**

**Common Issues & Solutions:**

ğŸ› **"401 Unauthorized" errors**
```bash
# Solution: Refresh browser to get new JWT token (8-hour expiry)
# Check token status
curl -H "Authorization: Bearer YOUR_TOKEN" http://localhost:8001/auth/me
```

ğŸ› **File upload processing fails**
```bash
# Solution: Restart Celery workers
python start_celery_worker.py

# Check task status
curl http://localhost:8001/task-status/YOUR_TASK_ID
```

ğŸ› **Celery worker not starting**
```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Check Redis connection
redis-cli ping

# Restart Redis via Docker
docker-compose restart redis
```

ğŸ› **Database connection errors**
```bash
# Verify PostgreSQL is running
pg_isready -h localhost -p 5432

# Check database exists
psql -U your_user -l | grep portfoliosql

# Initialize schema if needed
python initialize_schema_per_tenant.py
```

**Monitoring & Logs:**
- **API Logs**: Console output from FastAPI server
- **Celery Logs**: Worker output shows task processing
- **Frontend Logs**: Browser DevTools Console
- **Task Monitoring**: http://localhost:5555 (Flower dashboard)
- **Database Logs**: Enable query logging in PostgreSQL

## ğŸ”’ Security & Best Practices

### ğŸ›¡ï¸ **Data Protection**
- **Multi-Tenant Isolation**: Schema-per-tenant with proper access controls
- **JWT Security**: 8-hour token expiry with secure HTTP-only cookies
- **Input Sanitization**: SQL injection prevention via parameterized queries
- **File Validation**: Comprehensive Excel/CSV upload validation
- **User Data Isolation**: Each tenant's data completely isolated

### ğŸ” **Environment Security**
- **Secret Management**: All credentials in environment variables
- **Database Security**: Connection pooling with proper authentication
- **CORS Policy**: Restricted to allowed frontend origins
- **Google OAuth**: Secure third-party authentication flow
- **API Rate Limiting**: Built-in FastAPI security features

### ğŸ“Š **Performance & Monitoring**
- **Async Processing**: Non-blocking file uploads and queries
- **Connection Pooling**: Efficient database connection management
- **Task Queues**: Separate queues for different operation types
- **Monitoring Dashboard**: Real-time task and system monitoring
- **Error Tracking**: Comprehensive logging and error reporting

## ğŸš€ Production Deployment

### ğŸ—ï¸ **Production Setup**

**1. Environment Configuration:**
```bash
# Production environment variables
export DEBUG=false
export API_HOST=0.0.0.0
export API_PORT=8001
export JWT_ACCESS_TOKEN_EXPIRE_MINUTES=480
export ENABLE_SCHEMA_PER_TENANT=true
export ENABLE_AUTO_MIGRATION=true

# Database URLs for production
export DATABASE_URL="postgresql://user:pass@prod-db:5432/portfoliosql"
export PORTFOLIOSQL_DATABASE_URI="postgresql://user:pass@prod-db:5432/portfoliosql"

# Redis configuration
export REDIS_URL="redis://prod-redis:6379/0"
export CELERY_BROKER_URL="redis://prod-redis:6379/0"

# Multi-Agent System Configuration
export OPENAI_API_KEY="your_production_openai_key"
export AGENT_MODEL="gpt-4o"
export AGENT_TEMPERATURE="0.3"
export MAX_AGENT_ITERATIONS="10"
export AGENT_TIMEOUT_SECONDS="300"
export ENABLE_AGENT_CACHING="true"
export ENABLE_WEB_RESEARCH="true"
export ENABLE_CHART_GENERATION="true"
export MUTUAL_FUND_EXPERT_ENABLED="true"
export CELERY_RESULT_BACKEND="redis://prod-redis:6379/0"
```

**2. Production Deployment:**
```bash
# All-in-one production startup
python start_production.py

# Or with process manager
pm2 start start_production.py --name "sql-agent-prod"

# Monitor processes
pm2 monit
```

**3. Docker Deployment:**
```bash
# Start Redis container
docker-compose up -d redis

# Build and run application
docker build -t sql-agent .
docker run -d --name sql-agent-app -p 8001:8001 sql-agent
```

## ğŸ¤– Multi-Agent System Production Integration

### ğŸ—ï¸ **Multi-Agent Production Setup**

**1. OpenAI API Key Verification:**
```bash
# Verify API key works in production
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     -H "Content-Type: application/json" \
     -d '{"model": "gpt-4o", "messages": [{"role": "user", "content": "test"}], "max_tokens": 10}' \
     https://api.openai.com/v1/chat/completions
```

**2. Multi-Agent System Health Check:**
```bash
# Start multi-agent enabled server
python start_multi_agent_server.py

# Verify all 5 agents are healthy
curl http://localhost:8001/multi-agent/health | jq '.agents'

# Test system functionality
curl -X POST http://localhost:8001/multi-agent/test \
     -H "Content-Type: application/json"
```

**3. Performance Tuning for Production:**
```bash
# Production optimized settings
export MAX_AGENT_ITERATIONS=15
export AGENT_TIMEOUT_SECONDS=600  
export ENABLE_AGENT_CACHING=true
export WEB_SCRAPING_TIMEOUT=45
export MAX_CHART_DATA_POINTS=500
```

### ğŸ“Š **Multi-Agent Monitoring**

**Real-time System Monitoring:**
```bash
# Monitor agent performance
while true; do
  echo "=== Multi-Agent Health $(date) ==="
  curl -s http://localhost:8001/multi-agent/health | jq '.system_stats'
  sleep 30
done
```

**Agent Status Dashboard:**
```bash
# Get detailed agent status
curl http://localhost:8001/multi-agent/agents/status | jq '{
  orchestrator: .orchestrator.status,
  sql_agent: .sql_agent.databases_connected,
  expert_agent: .mutual_fund_expert.specialization,
  web_agent: .web_agent.sources_available,
  formatter: .data_formatter.chart_engine
}'
```

### ğŸ”§ **Multi-Agent Troubleshooting**

**Common Production Issues:**

ğŸ› **Agent timeout errors:**
```bash
# Increase timeout and check OpenAI API
export AGENT_TIMEOUT_SECONDS=600
curl -I https://api.openai.com/v1/models
```

ğŸ› **SQLAgent connection issues:**
```bash
# Refresh SQL agent cache
curl -X POST http://localhost:8001/multi-agent/agents/refresh/user@example.com

# Verify database discovery
curl http://localhost:8001/discovery/summary
```

ğŸ› **High memory usage:**
```bash
# Clear all agent caches
curl -X POST http://localhost:8001/multi-agent/agents/refresh/all

# Monitor memory usage
ps aux | grep python | grep multi_agent
```

### ğŸ“ˆ **Scaling & Performance**
- **Horizontal Scaling**: Add more Celery workers across machines
- **Database Scaling**: PostgreSQL read replicas for query performance
- **Load Balancing**: Multiple FastAPI instances behind load balancer
- **Caching**: Redis for session and query result caching
- **CDN**: Static asset delivery for frontend

## ğŸ† Features & Roadmap

### âœ… **Current Features**
- ğŸ“ **Multi-format Upload**: Excel, CSV with multi-sheet support
- ğŸ¤– **AI-Powered Queries**: Natural language to SQL conversion
- ğŸ‘¥ **Multi-Tenant Architecture**: Secure data isolation
- ğŸ”„ **Zero-Downtime Migration**: Database architecture migration
- ğŸ¨ **Modern UI**: Gemini-style chat interface
- ğŸ”‘ **Google OAuth**: Secure authentication
- âš¡ **Background Processing**: Async file processing
- ğŸ“ˆ **Task Monitoring**: Real-time progress tracking
- ğŸ“± **Responsive Design**: Mobile-friendly interface

### ğŸ”® **Future Enhancements**

**ğŸ¤– Multi-Agent System Evolution:**
- ğŸŒ **Real Web Integration**: Live market data APIs (BSE, NSE, Morningstar)
- ğŸ“ˆ **Advanced Visualizations**: Interactive charts with Plotly/D3.js
- ğŸ§  **Custom Agent Creation**: User-defined specialist agents
- ğŸ”„ **Workflow Designer**: Visual workflow builder interface
- ğŸ“Š **Portfolio Management**: Complete portfolio tracking and optimization
- ğŸš¨ **Smart Alerts**: AI-powered investment opportunity notifications

**ğŸ—ï¸ System Enhancements:**
- ğŸ“Š **Advanced Analytics**: Multi-dimensional data analysis
- ğŸ¨ **Dashboard Builder**: Custom dashboard creation
- ğŸ”„ **API Integrations**: Connect external financial data sources
- ğŸ“± **Mobile App**: Native mobile application with agent chat
- ğŸŒ **Multi-Language**: Internationalization support
- ğŸ” **Voice Interface**: Voice-to-query conversion

## ğŸ”§ Extending the Multi-Agent System

### ğŸ† **Adding New Agents**

**1. Create New Agent Class:**
```python
# agents/your_custom_agent.py
from agents.base_agent import BaseAgent
from agents.agent_configs import AgentMessage, AgentState

class YourCustomAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(
            agent_id="your_custom_agent",
            agent_type="specialist",
            description="Your agent description",
            config=config
        )
    
    async def process_message(self, message: AgentMessage, state: AgentState) -> AgentMessage:
        # Your custom agent logic here
        prompt = f"As a [your specialty] expert, {message.content}"
        response = await self.call_llm(prompt, message.context)
        
        return AgentMessage(
            content=response,
            agent_id=self.agent_id,
            message_type="response",
            context=message.context
        )
```

**2. Register Agent in Orchestrator:**
```python
# agents/multi_agent_orchestrator.py
# Add to __init__ method:
self.your_custom_agent = YourCustomAgent(self.config)

# Add to _route_to_agents method:
if "your_specialty_keyword" in query.lower():
    agents_to_use.append("your_custom_agent")
```

**3. Add Agent Configuration:**
```python
# settings.py - Add any new configuration variables
YOUR_CUSTOM_AGENT_ENABLED = get_bool_env("YOUR_CUSTOM_AGENT_ENABLED", True)

# agent_prompts.py - Add custom prompts
YOUR_CUSTOM_AGENT_PROMPT = """
You are a specialist in [your domain]. 
Provide expert analysis and recommendations.
"""
```

### ğŸ”„ **Adding New Workflows**

**1. Define Workflow in Orchestrator:**
```python
# agents/multi_agent_orchestrator.py
async def your_custom_workflow(self, query: str, user_email: str, context: dict) -> dict:
    """
    Custom workflow for specific use cases
    """
    workflow_steps = [
        ("your_custom_agent", "Analyze the request"),
        ("sql_agent", "Fetch relevant data"),
        ("data_formatter", "Format results")
    ]
    
    # Execute workflow steps
    results = {}
    for agent_name, task in workflow_steps:
        agent = getattr(self, agent_name)
        result = await agent.process_message(AgentMessage(
            content=f"{task}: {query}",
            context=context
        ), self.state)
        results[agent_name] = result
    
    return self._combine_agent_results(results)
```

**2. Add Workflow to Router:**
```python
# Add to _select_workflow method:
if "custom_analysis" in query.lower():
    return "your_custom_workflow"
```

### ğŸ“Š **Custom Data Sources Integration**

**1. External API Integration:**
```python
# agents/external_data_agent.py
class ExternalDataAgent(BaseAgent):
    async def fetch_market_data(self, symbol: str):
        # Integration with external APIs
        api_key = self.config.external_api_key
        url = f"https://api.example.com/data/{symbol}"
        
        async with httpx.AsyncClient() as client:
            response = await client.get(url, headers={"API-Key": api_key})
            return response.json()
```

**2. Database Integration:**
```python
# Add new database connections
class CustomDatabaseAgent(BaseAgent):
    async def connect_external_db(self):
        connection_string = self.config.external_db_url
        # Connect to external financial database
        return create_engine(connection_string)
```

### ğŸŒ **Production Deployment Extensions**

**1. Kubernetes Deployment:**
```yaml
# k8s/multi-agent-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-agent-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: multi-agent
  template:
    spec:
      containers:
      - name: multi-agent
        image: your-registry/multi-agent:latest
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
```

**2. Advanced Monitoring:**
```python
# monitoring/agent_metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Custom metrics for multi-agent system
agent_requests_total = Counter('agent_requests_total', 'Total agent requests', ['agent_name'])
agent_response_time = Histogram('agent_response_seconds', 'Agent response time')
active_sessions = Gauge('active_agent_sessions', 'Number of active agent sessions')
```

---

## ğŸ“ **Support & Documentation**

**ğŸ“š Core Documentation:**
- **Complete Guide**: This README.md (comprehensive system overview)
- **API Documentation**: http://localhost:8001/docs (Interactive Swagger UI)
- **API Reference**: http://localhost:8001/redoc (ReDoc format)
- **Task Monitor**: http://localhost:5555 (Flower dashboard)

**ğŸ¤– Multi-Agent System Documentation:**
- **System Health**: http://localhost:8001/multi-agent/health
- **Available Workflows**: http://localhost:8001/multi-agent/workflows
- **System Configuration**: http://localhost:8001/multi-agent/config
- **Agent Status**: http://localhost:8001/multi-agent/agents/status
- **Real-time Testing**: http://localhost:8001/multi-agent/test

**ğŸ” Development Resources:**
- **Database Discovery**: http://localhost:8001/discovery/summary
- **SQL Agent Status**: http://localhost:8001/health
- **Authentication**: http://localhost:8001/auth/me

**ğŸ› Support Channels:**
- **Issue Tracking**: Report bugs via GitHub issues
- **Feature Requests**: Suggest enhancements via GitHub discussions
- **System Logs**: Check console output for debugging
- **Performance Monitoring**: Use built-in health check endpoints

**Built with â¤ï¸ using cutting-edge AI technology**

**Powered by:** OpenAI GPT-4o | FastAPI | Next.js | PostgreSQL | Multi-Agent Intelligence

### Scaling Considerations
- **Database**: Use connection pooling and read replicas
- **Task Queue**: Scale RabbitMQ workers horizontally
- **Frontend**: Deploy to CDN for static assets
- **API**: Use load balancer for multiple backend instances

## ğŸ”§ Troubleshooting

### Common Issues

**Database Connection Errors**:
```bash
# Check database connectivity
psql -h localhost -U your_user -d portfoliosql
```

**File Upload Failures**:
- Check file size limits
- Verify file format compatibility
- Monitor RabbitMQ worker logs

**Query Errors**:
- Verify database schema
- Check user permissions
- Review SQL generation logs

**Frontend Issues**:
```bash
# Clear cache and reinstall
cd frontend
rm -rf node_modules package-lock.json
npm install
npm run dev
```

### Performance Issues
- Monitor database query performance
- Check RabbitMQ queue status
- Review memory usage of workers
- Optimize database indexes

### Getting Help
- Check API documentation at `/docs`
- Review application logs
- Verify environment configuration
- Test with minimal examples

## ğŸ“ˆ Performance Metrics

### Benchmarks
- **File Upload**: ~1MB/second processing rate
- **Query Response**: <2 seconds for complex queries
- **Concurrent Users**: Tested with 50+ simultaneous users
- **Database Operations**: Optimized for <100ms response time

### Monitoring
- **API Metrics**: Built-in FastAPI metrics
- **Database Performance**: Query execution time logging
- **Task Queue**: RabbitMQ management interface
- **Resource Usage**: Memory and CPU monitoring

## ğŸ¤ Contributing

### Development Workflow
1. Fork the repository
2. Create feature branch
3. Implement changes with tests
4. Update documentation
5. Submit pull request

### Code Standards
- **Python**: Follow PEP 8 guidelines
- **TypeScript**: Use strict type checking
- **SQL**: Use parameterized queries
- **Documentation**: Update README for new features

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT integration
- FastAPI team for the excellent framework
- Next.js team for the frontend framework
- PostgreSQL community for the robust database
- RabbitMQ team for the message queue system

---

**Version**: 4.0  
**Last Updated**: 2025-06-26  
**Maintained By**: Development Team
